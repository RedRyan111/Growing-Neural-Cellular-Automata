{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import IPython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython import display\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose image in image folder\n",
    "img_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of images from image folder\n",
    "img_folder = \"emoji-data-master\\\\emoji-data-master\\\\img-apple-64\"\n",
    "enteries = os.listdir(img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get image\n",
    "img = mpimg.imread(img_folder+\"\\\\\"+enteries[img_num])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert image from rgba to rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba_to_rgb(img):\n",
    "    temp_img = Image.fromarray(np.uint8(img*255))\n",
    "    background = Image.new(\"RGB\",(64,64), (255,255,255))\n",
    "    background.paste(temp_img,mask=temp_img.split()[3])\n",
    "    background = np.array(background)\n",
    "    background = (background - background.min())/(background.max()-background.min())\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rgba_to_rgb(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_image(state,num_channels):\n",
    "    state = state.permute(3,2,1,0)\n",
    "    state = torch.reshape(state,(64,64,1,num_channels))\n",
    "    state = torch.reshape(state,(64,64,num_channels))\n",
    "    state = state.narrow(2,0,3)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class big_NN(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(big_NN, self).__init__()\n",
    "        temp = num_channels*3\n",
    "        self.fc1 = nn.Linear(temp, temp)\n",
    "        self.fc2 = nn.Linear(temp, num_channels)\n",
    "        self.fc3 = nn.LeakyReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1 = self.fc3(self.fc1(x))\n",
    "        x2 = self.fc2(x1)*.01\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial state of all zeros except for one 'seed'\n",
    "def initial_state(num_channels):\n",
    "    state = torch.zeros((num_channels,1,64,64)).cuda()\n",
    "    for channel in range(num_channels):\n",
    "        for i in range(64):\n",
    "            for j in range(64):\n",
    "                if(i == 31 and j == 31):\n",
    "                    state[0][0][31][31] = 1.\n",
    "                    state[1][0][31][31] = 1.\n",
    "                    state[2][0][31][31] = 1.\n",
    "                    state[3][0][31][31] = 1.\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the state concatenated with the convolution of sobel_x and sobel_y on state\n",
    "def perception(state):\n",
    "    sobel_x = torch.FloatTensor([[-1,0,1],[-2,0,2],[-1,0,1]]).cuda()\n",
    "    sobel_y = torch.transpose(sobel_x,0,1).cuda()\n",
    "    \n",
    "    sobel_x = sobel_x.view(1,1,3,3)\n",
    "    sobel_y = sobel_y.view(1,1,3,3)\n",
    "    \n",
    "    big_state = F.pad(state,(1,1,1,1),\"circular\",0).cuda()\n",
    "    \n",
    "    grad_x = F.conv2d(big_state, sobel_x,stride=1,padding=0).cuda()\n",
    "    grad_y = F.conv2d(big_state, sobel_y,stride=1,padding=0).cuda()\n",
    "    \n",
    "    temp_state = torch.cat((state,grad_x,grad_y),0)\n",
    "    \n",
    "    return temp_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastically update the state\n",
    "def stochastic_update(state,state_update):\n",
    "    state_update = state_update.permute(1,0)\n",
    "    state_update = torch.reshape(state_update,(num_channels,1,64,64))            #reshape from 9,2 --> 2,1,3,3\n",
    "    update_mask = torch.FloatTensor(num_channels,1,64,64).uniform_().cuda()>.1   #stochastic update mask\n",
    "    state_update = torch.mul(state_update,update_mask)\n",
    "    return state_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alive Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update state where dimension tensor is greater than .1\n",
    "def alive_masking(state,state_update):\n",
    "    alive = F.max_pool2d(state[3],kernel_size=3,stride=1,padding=1).cuda()\n",
    "    state = torch.where((alive>.1),state+state_update,state).cuda()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 16\n",
    "epochs = 1000\n",
    "steps = 150\n",
    "\n",
    "model = big_NN(num_channels)\n",
    "model = model.cuda()\n",
    "\n",
    "mse = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "images = []\n",
    "loss_list = []\n",
    "img = torch.FloatTensor(img).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    state = initial_state(num_channels).cuda()\n",
    "    \n",
    "    #Run neural cellular automata\n",
    "    for step in range(steps):\n",
    "        conv_state = perception(state)\n",
    "        conv_state = torch.reshape(conv_state.permute(3,2,1,0),(1*64*64,num_channels*3))\n",
    "        state_update = model(conv_state)\n",
    "        state_update = stochastic_update(state,state_update)\n",
    "\n",
    "        state = alive_masking(state,state_update)\n",
    "\n",
    "    temp_state = state_to_image(state,num_channels)\n",
    "    \n",
    "    #update model\n",
    "    loss = mse(temp_state,img)\n",
    "    loss_list.append(float(loss))\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    print(\"Epoch: {}    loss: {}\".format(epoch,loss.detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(temp_state.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(loss_list))],loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cellular automata without training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "state = initial_state(num_channels)\n",
    "for step in range(steps):\n",
    "    conv_state = perception(state)\n",
    "    conv_state = torch.reshape(conv_state.permute(3,2,1,0),(1*64*64,num_channels*3))\n",
    "    state_update = model(conv_state)\n",
    "    state_update = stochastic_update(state,state_update)\n",
    "\n",
    "    state = alive_masking(state,state_update)\n",
    "    temp_state = state_to_image(state,num_channels)\n",
    "    images.append(temp_state.cpu().detach().numpy())\n",
    "    \n",
    "loss = mse(temp_state,img)\n",
    "print(\"Epoch: {}    loss: {}\".format(epoch,loss.detach()))\n",
    "state = initial_state(num_channels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert list of images to GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [Image.fromarray(np.uint8(image*100.)) for image in images]\n",
    "image_list = [image.resize((640,640)) for image in image_list]\n",
    "image_list[0].save('growing_phase.gif',save_all=True,append_images=image_list[1:],optimize=False,duration=40,loops=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gifPath = Path(\"growing_phase.gif\")\n",
    "with open(gifPath,'rb') as f:\n",
    "    display.Image(data=f.read(),format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
